# 1Âº Hackathon em Controle Social: Desafio Participa DF
## Categoria: Acesso Ã  InformaÃ§Ã£o

### Nome do Projeto
**ClassificaÃ§Ã£o AutomÃ¡tica de SolicitaÃ§Ãµes com Dados Pessoais (PII)**

### DescriÃ§Ã£o do Projeto
Este projeto tem como objetivo identificar automaticamente se uma solicitaÃ§Ã£o de acesso Ã  informaÃ§Ã£o contÃ©m **dados pessoais sensÃ­veis**, auxiliando Ã³rgÃ£os pÃºblicos no tratamento adequado das demandas conforme a Lei Geral de ProteÃ§Ã£o de Dados (LGPD).

A soluÃ§Ã£o utiliza um modelo de **Processamento de Linguagem Natural (PLN)** treinado para classificar textos extraÃ­dos de solicitaÃ§Ãµes do Participa DF, indicando se hÃ¡ ou nÃ£o presenÃ§a de dados pessoais. O foco Ã© apoiar a transparÃªncia pÃºblica com responsabilidade e seguranÃ§a da informaÃ§Ã£o.

---

## Tecnologias Utilizadas
- Python 4.14
- Pandas
- NumPy
- Scikit-learn
- Transformers (Hugging Face)
- PyTorch
- Jupyter Notebook

---

## Autores
- **Autora:** Amanda dos Santos Pereira  
- **Coautora:** Suzany de Almeida Lima  

---

# 1. InstruÃ§Ãµes de InstalaÃ§Ã£o e DependÃªncias

## 1.1 PrÃ©-requisitos
Antes de iniciar, certifique-se de ter instalado:

- Python **3.9 ou superior**
- Git
- Ambiente Windows (testado em Windows 10+)
- Acesso Ã  internet para download do modelo

> âš ï¸ **ObservaÃ§Ã£o:** Verifique a **compatibilidade do Python usado**, pois essa versÃ£o pode nÃ£o ser estÃ¡vel em Python recentes que nÃ£o Ã© suportada pelas bibliotecas utilizadas.

---

## 1.2 Gerenciamento de Pacotes
O projeto utiliza um arquivo `requirements.txt`, que contÃ©m todas as dependÃªncias necessÃ¡rias para execuÃ§Ã£o, permitindo a instalaÃ§Ã£o automatizada do ambiente.

Exemplo de dependÃªncias incluÃ­das:
```txt
pandas
numpy
torch
transformers
scikit-learn
```

## 1.3 CriaÃ§Ã£o e ConfiguraÃ§Ã£o do Ambiente

#### 1.3.1 Abra um terminal na pasta raiz do projeto.
Crie um ambiente virtual:
`python -m venv .venv`

#### 1.3.2 Ative o ambiente virtual:
`.venv\Scripts\Activate.ps1`


#### 1.3.3 Instale as dependÃªncias:
`pip install -r requirements.txt`

## 2. CriaÃ§Ã£o do Dataset
O dataset foi construÃ­do a partir de solicitaÃ§Ãµes reais disponibilizadas pelo `portaldatransparencia.gov.br` em Busca de Pedidos e Respostas dos anos de 2025 e 2024.

Etapas realizadas:
- Limpeza de textos
- NormalizaÃ§Ã£o (minÃºsculas, remoÃ§Ã£o de caracteres especiais)
- AnonimizaÃ§Ã£o
- Rotulagem supervisionada (possui_dados_pessoais = True/False)
- ValidaÃ§Ã£o dos rÃ³tulos
- Esses processos garantem consistÃªncia e confiabilidade para o treinamento do modelo.
- As etapas de criaÃ§Ã£o do dataset estÃ£o documentadas no diretÃ³rio:
`pipelines/dataset_generation`


## 3 Treinamento e PublicaÃ§Ã£o do Modelo

### O treinamento do modelo:

O modelo treinado no notebook `pipelines/training/model_training.ipynb` foi publicado no Hugging Face
ğŸ”— ([https://huggingface.co/amanda2703/pii-distilbert-hackathon](https://huggingface.co/amanda2703/pii-distilbert-hackathon)).


#### Etapas do treinamento:

- TokenizaÃ§Ã£o dos textos

- Fine-tuning do modelo DistilBERT

- AvaliaÃ§Ã£o com mÃ©tricas de classificaÃ§Ã£o

- Salvamento do modelo final


## 4. Como Rodar o Projeto (Windows)
Requisitos
- Python
- ExecuÃ§Ã£o
- ApÃ³s configurar o ambiente, execute:
- python app/inference.py

> âš ï¸ **ObservaÃ§Ã£o:** Na primeira execuÃ§Ã£o do script, Ã© esperado um tempo maior de processamento, pois o modelo serÃ¡ baixado e armazenado em cache. ApÃ³s essa etapa inicial, as execuÃ§Ãµes subsequentes tendem a ser significativamente mais rÃ¡pidas.

---
-  ConfiguraÃ§Ãµes do Script

No arquivo app/inference.py, estÃ£o definidas as seguintes variÃ¡veis:

```python
MODEL_ID = 'amanda2703/pii-distilbert-hackathon'
FILE_PATH = './app/amostras.csv'
COLUMN_TEXT = 'solicitacao'
COLUMN_LABEL = 'possui_dados_pessoais'
```

DescriÃ§Ã£o:

* **FILE_PATH**: define o caminho do arquivo CSV que serÃ¡ analisado. O arquivo utilizado Ã© o disponibilizado pelo Hackathon, no qual as classificaÃ§Ãµes foram criadas manualmente.
* **COLUMN_TEXT**: indica a coluna que contÃ©m o texto a ser classificado.
* **COLUMN_LABEL**: indica a coluna utilizada para validaÃ§Ã£o das classificaÃ§Ãµes.
Essas trÃªs variÃ¡veis podem ser ajustadas conforme o arquivo submetido, desde que o formato seja CSV e que a coluna definida em `COLUMN_LABEL` contenha valores booleanos.


> âš ï¸ **Regras Extras:** 

O arquivo de entrada deve estar no formato CSV.
A coluna definida em COLUMN_TEXT nÃ£o pode conter valores nulos.
A coluna COLUMN_LABEL deve conter valores booleanos (True ou False).
Caso a coluna de validaÃ§Ã£o nÃ£o exista, o script pode ser adaptado para inferÃªncia pura (sem validaÃ§Ã£o).
---

## 5. InstruÃ§Ãµes de ExecuÃ§Ã£o
### 5.1 Comando Principal
python app/inference.py

### 5.2 Formato dos Dados

Entrada:
- Arquivo CSV contendo:
- Uma coluna de texto (solicitacao)
- Opcionalmente, uma coluna de rÃ³tulo booleano (possui_dados_pessoais)

SaÃ­da:
- ClassificaÃ§Ã£o automÃ¡tica por linha
- ComparaÃ§Ã£o com rÃ³tulos reais (quando disponÃ­veis)
- MÃ©tricas de desempenho exibidas no console

## 6. Clareza e OrganizaÃ§Ã£o
### 6.1 ComentÃ¡rios no CÃ³digo

O cÃ³digo-fonte contÃ©m comentÃ¡rios explicativos em:

- FunÃ§Ãµes de carregamento do modelo
- Processamento de dados

- Etapas de inferÃªncia e validaÃ§Ã£o
Isso facilita a compreensÃ£o e manutenÃ§Ã£o do projeto.

### 6.2 Estrutura de DiretÃ³rios
```
.
â”œâ”€â”€ app/ 
â”‚   â”œâ”€â”€ inference.py 
â”‚   â””â”€â”€ amostras.csv 
â”œâ”€â”€ pipelines/ 
â”‚   â”œâ”€â”€ dataset_generation/ 
â”‚   â””â”€â”€ training/ 
â”œâ”€â”€ requirements.txt 
â””â”€â”€ README.md 
```

A estrutura separa claramente dados, pipelines, scripts e documentaÃ§Ã£o, seguindo boas prÃ¡ticas de projetos em ciÃªncia de dados.
