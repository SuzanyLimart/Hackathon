# 1¬∫ Hackathon em Controle Social: Desafio Participa DF
## Categoria: Acesso √† Informa√ß√£o

### Nome do Projeto
**Classifica√ß√£o Autom√°tica de Solicita√ß√µes com Dados Pessoais (PII)**

### Descri√ß√£o do Projeto
Este projeto tem como objetivo identificar automaticamente se uma solicita√ß√£o de acesso √† informa√ß√£o cont√©m **dados pessoais sens√≠veis**, auxiliando √≥rg√£os p√∫blicos no tratamento adequado das demandas conforme a Lei Geral de Prote√ß√£o de Dados (LGPD).

A solu√ß√£o utiliza um modelo de **Processamento de Linguagem Natural (PLN)** treinado para classificar textos extra√≠dos de solicita√ß√µes do Participa DF, indicando se h√° ou n√£o presen√ßa de dados pessoais. O foco √© apoiar a transpar√™ncia p√∫blica com responsabilidade e seguran√ßa da informa√ß√£o.

---

## Tecnologias Utilizadas
- Python 4.14
- Pandas
- NumPy
- Scikit-learn
- Transformers (Hugging Face)
- PyTorch
- Jupyter Notebook

---

## Autores
- **Autora:** Amanda dos Santos Pereira  
- **Coautora:** Suzany de Almeida Lima  

---

# 1. Instru√ß√µes de Instala√ß√£o e Depend√™ncias

## 1.1 Pr√©-requisitos
Antes de iniciar, certifique-se de ter instalado:

- Python **3.9 ou superior**
- Git
- Ambiente Windows (testado em Windows 10+)
- Acesso √† internet para download do modelo

> ‚ö†Ô∏è **Observa√ß√£o:** Verifique a **compatibilidade do Python usado**, pois essa vers√£o pode n√£o ser est√°vel em Python recentes que n√£o √© suportada pelas bibliotecas utilizadas.

---

## 1.2 Gerenciamento de Pacotes
O projeto utiliza um arquivo `requirements.txt`, que cont√©m todas as depend√™ncias necess√°rias para execu√ß√£o, permitindo a instala√ß√£o automatizada do ambiente.

Exemplo de depend√™ncias inclu√≠das:
```txt
pandas
numpy
torch
transformers
scikit-learn
```

## 1.3 Cria√ß√£o e Configura√ß√£o do Ambiente

#### 1.3.1 Abra um terminal na pasta raiz do projeto.
Crie um ambiente virtual:
`python -m venv .venv`

#### 1.3.2 Ative o ambiente virtual:
`.venv\Scripts\Activate.ps1`


#### 1.3.3 Instale as depend√™ncias:
`pip install -r requirements.txt`

## 2. Cria√ß√£o do Dataset
O dataset foi constru√≠do a partir de solicita√ß√µes reais disponibilizadas pelo `portaldatransparencia.gov.br` em Busca de Pedidos e Respostas dos anos de 2025 e 2024.

Etapas realizadas:
- Limpeza de textos
- Normaliza√ß√£o (min√∫sculas, remo√ß√£o de caracteres especiais)
- Anonimiza√ß√£o
- Rotulagem supervisionada (possui_dados_pessoais = True/False)
- Valida√ß√£o dos r√≥tulos
- Esses processos garantem consist√™ncia e confiabilidade para o treinamento do modelo.
- As etapas de cria√ß√£o do dataset est√£o documentadas no diret√≥rio:
`pipelines/dataset_generation`


## 3 Treinamento e Publica√ß√£o do Modelo

### O treinamento do modelo foi realizado no notebook:
`pipelines/training/model_training.ipynb`

#### Etapas do treinamento:

- Tokeniza√ß√£o dos textos

- Fine-tuning do modelo DistilBERT

- Avalia√ß√£o com m√©tricas de classifica√ß√£o

- Salvamento do modelo final

O modelo treinado foi publicado no Hugging Face Hub:

`üîó https://huggingface.co/amanda2703/pii-distilbert-hackathon`

## 4. Como Rodar o Projeto (Windows)
Requisitos

- Python 3.9+
- Execu√ß√£o
- Ap√≥s configurar o ambiente, execute:
- python app/inference.py


#### Na primeira execu√ß√£o, o script realizar√° o download autom√°tico do modelo publicado no Hugging Face, o que pode levar alguns minutos. Nas execu√ß√µes seguintes, o modelo ser√° carregado a partir do cache local, tornando o processo mais r√°pido.

-  Configura√ß√µes do Script

No arquivo app/inference.py, est√£o definidas as seguintes vari√°veis:

```python
MODEL_ID = 'amanda2703/pii-distilbert-hackathon'
FILE_PATH = './app/amostras.csv'
COLUMN_TEXT = 'solicitacao'
COLUMN_LABEL = 'possui_dados_pessoais'
```

Descri√ß√£o:

```python
`MODEL_ID: identificador do modelo publicado no Hugging Face.
`FILE_PATH: caminho do arquivo CSV a ser analisado.`
`COLUMN_TEXT: coluna que cont√©m o texto da solicita√ß√£o.
COLUMN_LABEL: coluna utilizada para valida√ß√£o dos resultados.`
```

Regras Extras:

O arquivo de entrada deve estar no formato CSV.
A coluna definida em COLUMN_TEXT n√£o pode conter valores nulos.
A coluna COLUMN_LABEL deve conter valores booleanos (True ou False).
Caso a coluna de valida√ß√£o n√£o exista, o script pode ser adaptado para infer√™ncia pura (sem valida√ß√£o).

## 5. Instru√ß√µes de Execu√ß√£o
### 5.1 Comando Principal
python app/inference.py

### 5.2 Formato dos Dados

Entrada:
- Arquivo CSV contendo:
- Uma coluna de texto (solicitacao)
- Opcionalmente, uma coluna de r√≥tulo booleano (possui_dados_pessoais)

Sa√≠da:
- Classifica√ß√£o autom√°tica por linha
- Compara√ß√£o com r√≥tulos reais (quando dispon√≠veis)
- M√©tricas de desempenho exibidas no console

## 6. Clareza e Organiza√ß√£o
### 6.1 Coment√°rios no C√≥digo

O c√≥digo-fonte cont√©m coment√°rios explicativos em:

- Fun√ß√µes de carregamento do modelo
- Processamento de dados

- Etapas de infer√™ncia e valida√ß√£o
Isso facilita a compreens√£o e manuten√ß√£o do projeto.

### 6.2 Estrutura de Diret√≥rios
```
.
‚îú‚îÄ‚îÄ app/ 
‚îÇ   ‚îú‚îÄ‚îÄ inference.py 
‚îÇ   ‚îî‚îÄ‚îÄ amostras.csv 
‚îú‚îÄ‚îÄ pipelines/ 
‚îÇ   ‚îú‚îÄ‚îÄ dataset_generation/ 
‚îÇ   ‚îî‚îÄ‚îÄ training/ 
‚îú‚îÄ‚îÄ requirements.txt 
‚îî‚îÄ‚îÄ README.md 
```

A estrutura separa claramente dados, pipelines, scripts e documenta√ß√£o, seguindo boas pr√°ticas de projetos em ci√™ncia de dados.
